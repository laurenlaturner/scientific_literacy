## Clear the environment
rm(list=ls())
## Load necessary libraries
library(readxl)
library(lme4) # for mixed models if class random effects are needed
library(dplyr) # for transformations
library(glmmTMB) # for beta regression
library(betareg) # different beta regression package
library(car) # for diagnostic plots
library(psych) # for descriptive stats
library(ggplot2) # for data visualization
library(MuMIn) # for AIC model reduction
library(performance) # for pseudo-R^2
## Load data
df <- read_excel("C:\Users\laure\Desktop\scientific_literacy\for_jupyter\organized r scripts\data.xlsx",
## Clear the environment
rm(list=ls())
## Load necessary libraries
library(readxl)
library(lme4) # for mixed models if class random effects are needed
library(dplyr) # for transformations
library(glmmTMB) # for beta regression
library(betareg) # different beta regression package
library(car) # for diagnostic plots
library(psych) # for descriptive stats
library(ggplot2) # for data visualization
library(MuMIn) # for AIC model reduction
library(performance) # for pseudo-R^2
## Load data
df <- read_excel("C:\\Users\\laure\\Desktop\\scientific_literacy\\for_jupyter\\organized r scripts\\data.xlsx",
sheet="Sheet 1")
## Clear the environment
rm(list=ls())
## Load necessary libraries
library(readxl)
library(lme4) # for mixed models if class random effects are needed
library(dplyr) # for transformations
library(glmmTMB) # for beta regression
library(betareg) # different beta regression package
library(car) # for diagnostic plots
library(psych) # for descriptive stats
library(ggplot2) # for data visualization
library(MuMIn) # for AIC model reduction
library(performance) # for pseudo-R^2
## Load data
df <- read_excel("C:/Users/laure/Desktop/scientific_literacy/for_jupyter/organized r scripts/data.xlsx",
sheet="Sheet 1")
file.exists("C:/Users/laure/Desktop/scientific_literacy/for_jupyter/organized r scripts/data.xlsx")
## Clear the environment
rm(list=ls())
## Load necessary libraries
library(readxl)
library(lme4) # for mixed models if class random effects are needed
library(dplyr) # for transformations
library(glmmTMB) # for beta regression
library(betareg) # different beta regression package
library(car) # for diagnostic plots
library(psych) # for descriptive stats
library(ggplot2) # for data visualization
library(MuMIn) # for AIC model reduction
library(performance) # for pseudo-R^2
## Load data
df <- read_excel("C:/Users/laure/Desktop/scientific_literacy/for_jupyter/data.xlsx",
sheet="Sheet 1")
## Load data
df <- read_excel("C:/Users/laure/Desktop/scientific_literacy/for_jupyter/data.xlsx",
sheet="Sheet1")
# Descriptive statistics for overall understanding of data
summary(df)
describe(df)  # from psych package
# EDA: Histogram for normality check on pre/post test scores
hist(df$`pre SELF average`)
hist(df$`post SELF average`)
mean(df$`pre SELF average`, na.rm = TRUE)
sd(df$`pre SELF average`, na.rm = TRUE)
hist(df$`pre TOSLS score`)
hist(df$`post TOSLS score`)
mean(df$`pre TOSLS score`, na.rm = TRUE)
sd(df$`pre TOSLS score`, na.rm = TRUE)
# Standardization of variables
df.std <- df
df.std$`post SELF average` <- c(scale(df$`post SELF average`))
df.std$`pre SELF average` <- c(scale(df$`pre SELF average`))
df.std$`post TOSLS score` <- c(scale(df$`post TOSLS score`))
df.std$`pre TOSLS score` <- c(scale(df$`pre TOSLS score`))
## Likert Transformation (Centered between -1 and 1)
transform_likert <- function(x) {
return((x - 3) / 2)
}
pre_questions <- paste0("pre SELF -  Q", 1:8)
post_questions <- paste0("post SELF -  Q", 1:8)
## Apply the transformation for centering Likert-scale data
df.std <- df %>%
mutate(across(all_of(pre_questions), transform_likert)) %>%
mutate(across(all_of(post_questions), transform_likert))
# Calculate delta (change in scores)
df.std$delta_self <- df.std$`post SELF average` - df.std$`pre SELF average`
df.std$delta_test <- df.std$`post TOSLS score` - df.std$`pre TOSLS score`
# Calculate delta of percentages
df.std$delta_test_percent <- df.std$delta_test/28
# Calculate percentages of scores (absolute values, out of 28)
df.std$perc_test <- df.std$`post TOSLS score`/28
# Convert 0's and 1's to be slightly shifted
df.std$perc_test[df.std$perc_test == 0] <- 0.0005
df.std$perc_test[df.std$perc_test == 1] <- 0.9995
## 2 proportion z-test on Change in TOSLS per BLS objective
## Clear the environment
rm(list=ls())
## Load data
df <- read_excel("C:/Users/laure/Desktop/scientific_literacy/for_jupyter/data.xlsx",
sheet="Sheet3")
library(tidyverse)
library(janitor)
# Clean up column names to make them easier to reference
df <- df %>% clean_names()
# Check cleaned column names
# names(df)
# pre_sum_correct, pre_total, post_sum_correct, post_total
# Add a column with p-values for each row
df <- df %>%
mutate(
p_value = pmap_dbl(
list(pre_sum_correct, pre_total, post_sum_correct, post_total),
function(pre_s, pre_n, post_s, post_n) {
prop.test(x = c(pre_s, post_s), n = c(pre_n, post_n), correct = FALSE)$p.value
}
)
)
library(dplyr)
library(janitor)
library(knitr)
# Assuming df is already cleaned and has the p_value column
pretty_df <- df %>%
mutate(
`Pre %` = round(pre_sum_correct / pre_total, 3),
`Post %` = round(post_sum_correct / post_total, 3),
`P-value` = signif(p_value, 3),
`Significant?` = case_when(
p_value < 0.001 ~ "*** (p < .001)",
p_value < 0.01  ~ "** (p < .01)",
p_value < 0.05  ~ "* (p < .05)",
TRUE ~ "No"
)
) %>%
select(Name = 1, `Pre %`, `Post %`, `P-value`, `Significant?`)
# Print it nicely
kable(pretty_df, align = 'lcccl', caption = "Pre/Post Percentages and Significance Test Results")
## Pre/Post general analysis (Wilcoxon test, Spearman correlation, and paired t-test)
wilcox_result <- wilcox.test(df$`post SELF average`, df$`pre SELF average`,
paired = TRUE, alternative = "greater")
## Clear the environment
rm(list=ls())
## Load necessary libraries
library(readxl)
library(lme4) # for mixed models if class random effects are needed
library(dplyr) # for transformations
library(glmmTMB) # for beta regression
library(betareg) # different beta regression package
library(car) # for diagnostic plots
library(psych) # for descriptive stats
library(ggplot2) # for data visualization
library(MuMIn) # for AIC model reduction
library(performance) # for pseudo-R^2
## Load data
df <- read_excel("C:/Users/laure/Desktop/scientific_literacy/for_jupyter/data.xlsx",
sheet="Sheet1")
# Descriptive statistics for overall understanding of data
summary(df)
describe(df)  # from psych package
# EDA: Histogram for normality check on pre/post test scores
hist(df$`pre SELF average`)
hist(df$`post SELF average`)
mean(df$`pre SELF average`, na.rm = TRUE)
sd(df$`pre SELF average`, na.rm = TRUE)
hist(df$`pre TOSLS score`)
hist(df$`post TOSLS score`)
mean(df$`pre TOSLS score`, na.rm = TRUE)
sd(df$`pre TOSLS score`, na.rm = TRUE)
# Standardization of variables
df.std <- df
df.std$`post SELF average` <- c(scale(df$`post SELF average`))
df.std$`pre SELF average` <- c(scale(df$`pre SELF average`))
df.std$`post TOSLS score` <- c(scale(df$`post TOSLS score`))
df.std$`pre TOSLS score` <- c(scale(df$`pre TOSLS score`))
## Likert Transformation (Centered between -1 and 1)
transform_likert <- function(x) {
return((x - 3) / 2)
}
pre_questions <- paste0("pre SELF -  Q", 1:8)
post_questions <- paste0("post SELF -  Q", 1:8)
## Apply the transformation for centering Likert-scale data
df.std <- df %>%
mutate(across(all_of(pre_questions), transform_likert)) %>%
mutate(across(all_of(post_questions), transform_likert))
# Calculate delta (change in scores)
df.std$delta_self <- df.std$`post SELF average` - df.std$`pre SELF average`
df.std$delta_test <- df.std$`post TOSLS score` - df.std$`pre TOSLS score`
# Calculate delta of percentages
df.std$delta_test_percent <- df.std$delta_test/28
# Calculate percentages of scores (absolute values, out of 28)
df.std$perc_test <- df.std$`post TOSLS score`/28
# Convert 0's and 1's to be slightly shifted
df.std$perc_test[df.std$perc_test == 0] <- 0.0005
df.std$perc_test[df.std$perc_test == 1] <- 0.9995
## Pre/Post general analysis (Wilcoxon test, Spearman correlation, and paired t-test)
wilcox_result <- wilcox.test(df$`post SELF average`, df$`pre SELF average`,
paired = TRUE, alternative = "greater")
spearman_r <- cor(df$`pre SELF average`, df$`post SELF average`, method = "spearman",
use = "complete.obs")
kendall_r <- cor(df$`pre SELF average`, df$`post SELF average`, method = "kendall",
use = "complete.obs")
t_result <- t.test(df$`pre TOSLS score`, df$`post TOSLS score`, paired = TRUE)
## --- Visualization for Wilcoxon test ---
# Create long-format
df_self_long <- data.frame(
ID = rep(1:nrow(df), each = 2),
Time = rep(c("Pre", "Post"), times = nrow(df)),
Score = c(df$`pre SELF average`, df$`post SELF average`)
)
df_self_long$Time <- factor(df_self_long$Time, levels = c("Pre", "Post"))
# Calculate medians
median_pre_self <- median(df$`pre SELF average`, na.rm = TRUE)
median_post_self <- median(df$`post SELF average`, na.rm = TRUE)
# Prepare median line data
trend_data <- data.frame(Time = c("Pre", "Post"),
Score = c(median_pre_self, median_post_self),
Group = "Median Trend")
# Plot
ggplot(df_self_long, aes(x = Time, y = Score, group = ID)) +
geom_line(alpha = 0.4, color = "gray") +
geom_point(aes(color = Time), size = 2) +
geom_line(data = trend_data,
aes(x = Time, y = Score, linetype = Group, group = Group),
color = "black", size = 1.2) +
scale_linetype_manual(name = "", values = c("Median Trend" = "solid")) +
scale_color_manual(values = c("Pre" = "darkred", "Post" = "darkgreen"),
guide = "none") +
labs(title = "SELF Assessment Scores: Wilcoxon Signed-Rank Test",
subtitle = paste0("p-value = ", signif(wilcox_result$p.value, 3)),
x = "", y = "SELF Score") +
theme_minimal() +
theme(legend.title = element_blank(),
legend.position = "bottom")
## --- Visualization for Correlations ---
# Plot
ggplot(df, aes(x = `pre SELF average`, y = `post SELF average`)) +
geom_point(color = "steelblue", size = 2) +
geom_smooth(method = "lm", se = FALSE, linetype = "dashed", color = "black") +
labs(title = "SELF Assessment Correlation",
subtitle = paste0("Spearman = ", round(spearman_r, 2),
" | Kendall = ", round(kendall_r, 2)),
x = "Pre SELF Score", y = "Post SELF Score") +
theme_minimal()
## --- Visualization for T-test ---
# Create long-format manually
df_tosls_long <- data.frame(
ID = rep(1:nrow(df), each = 2),
Time = rep(c("Pre", "Post"), times = nrow(df)),
Score = c(df$`pre TOSLS score`, df$`post TOSLS score`)
)
df_tosls_long$Time <- factor(df_tosls_long$Time, levels = c("Pre", "Post"))
# Calculate means
mean_pre_tosls <- mean(df$`pre TOSLS score`, na.rm = TRUE)
mean_post_tosls <- mean(df$`post TOSLS score`, na.rm = TRUE)
# Prepare mean line data
trend_data <- data.frame(Time = c("Pre", "Post"),
Score = c(mean_pre_tosls, mean_post_tosls),
Group = "Mean Trend")
# Plot
ggplot(df_tosls_long, aes(x = Time, y = Score, group = ID)) +
geom_line(alpha = 0.4, color = "gray") +
geom_point(aes(color = Time), size = 2) +
geom_line(data = trend_data,
aes(x = Time, y = Score, linetype = Group, group = Group),
color = "black", size = 1.2) +
scale_linetype_manual(name = "Mean Line", values = c("Mean Trend" = "solid")) +
scale_color_manual(name = "Mean Line", values = c("Mean Trend" = "black")) +
scale_color_manual(values = c("Pre" = "darkblue", "Post" = "darkorange"), guide = "none") +
labs(title = "TOSLS Scores: Paired t-Test",
subtitle = paste0("p-value = ", signif(t_result$p.value, 3)),
x = "", y = "TOSLS Score") +
theme_minimal() +
theme(legend.title = element_blank(),
legend.position = "bottom")
## --- Visualization for SELF Q's vs. TOSLS score ---
# Initialize empty list to store correlations
cor_results <- data.frame(Question = character(),
Spearman = numeric(),
p_value = numeric(),
stringsAsFactors = FALSE)
# Loop over each post question
for (q in post_questions) {
corr <- cor.test(df[[q]], df$`post TOSLS score`, method = "spearman")
cor_results <- rbind(cor_results,
data.frame(Question = q,
Spearman = corr$estimate,
p_value = corr$p.value))
}
# Clean question labels for plot
cor_results$Question <- sub(".*Q", "Q", cor_results$Question)
# Plot correlations
ggplot(cor_results, aes(x = reorder(Question, Spearman), y = Spearman)) +
geom_col(fill = "skyblue") +
geom_text(aes(label = round(Spearman, 2)), vjust = -0.5) +
labs(title = "Spearman Correlation: Post-SELF Questions vs Post-TOSLS Score",
x = "Post SELF Question",
y = "Spearman Correlation") +
theme_minimal() +
coord_flip()
## --- Each SELF Q compared to TOSLS percent---
# Prepare long-format data
df_extra <- df.std[, c("perc_test", "Section")]
self_questions <- names(df)[grepl("^post SELF -  Q", names(df))]
df_likert <- df[, self_questions]
df_combined <- cbind(df_extra, df_likert)
df_long <- reshape(
data = df_combined,
varying = self_questions,
v.names = "Score",
timevar = "Question",
times = self_questions,
direction = "long"
)
df_long <- na.omit(df_long)
df_long$Section <- as.factor(df_long$Section)
df_long$Question <- as.factor(df_long$Question)
# Visualization
ggplot(df_long, aes(x = Score, y = perc_test, color = Section)) +
geom_point(alpha = 0.5, size = 1.2) +
geom_smooth(method = "lm", se = FALSE, linewidth = 1) +
facet_wrap(~ Question, ncol = 3) +
scale_x_continuous(breaks = 1:5, limits = c(1, 5)) +
labs(
title = "Post TOSLS Percent vs Individual Post SELF Questions",
x = "Post SELF Question Score",
y = "Post TOSLS Percent"
) +
scale_color_manual(values = c("2" = "blue", "3" = "red")) +
theme_minimal()
# ---------------------------------------------------------
# Analysis: Effect of CHANGE in Student's Self-Perception
#           on CHANGE in TOSLS Score
# ---------------------------------------------------------
# Ensure Section is a factor
df.std$Section <- as.factor(df.std$Section)
## -----------------------------------------------
## 1. Beta Regression Model: perc_test ~ delta_self + Section
## -----------------------------------------------
# Fit Beta regression model
m_beta <- betareg(perc_test ~ delta_self + Section, data = df.std)
summary(m_beta)
# Inverse logit function to back-transform to response scale
inv_logit <- function(x) exp(x) / (1 + exp(x))
# Identify rows with complete predictor data
complete_rows <- complete.cases(df.std[, c("delta_self", "Section")])
# Predict fitted values on link scale for complete rows only
pred_link <- predict(m_beta, newdata = df.std[complete_rows, ], type = "link")
# Initialize predicted_beta column with NA
df.std$predicted_beta <- NA
# Assign back-transformed predictions to corresponding rows
df.std$predicted_beta[complete_rows] <- inv_logit(pred_link)
# Visualization: points + predicted lines by Section
ggplot(df.std, aes(x = delta_self, y = perc_test, color = Section)) +
geom_point(alpha = 0.7) +
geom_line(aes(y = predicted_beta), linewidth = 1) +
labs(
title = "Beta Regression: Percentage TOSLS vs Change in SELF (by Section)",
x = "Change in SELF Score (delta_self)",
y = "Percentage TOSLS Score (perc_test)"
) +
scale_color_manual(values = c("2" = "blue", "3" = "red")) +
theme_minimal()
## -----------------------------------------------
## 2. Mixed-Effects Beta Regression: perc_test ~ `post SELF average` + (1 | Section)
## -----------------------------------------------
m_mixed_beta <- glmmTMB(perc_test ~ `post SELF average` + (1 | Section),
family = beta_family(),
data = df.std)
summary(m_mixed_beta)
# Handle missing data for prediction
complete_rows_mixed <- complete.cases(df.std[, c("post SELF average", "Section")])
pred_mixed <- predict(m_mixed_beta, newdata = df.std[complete_rows_mixed, ], type = "response")
df.std$predicted_mixed_beta <- NA
df.std$predicted_mixed_beta[complete_rows_mixed] <- pred_mixed
# Visualization
ggplot(df.std, aes(x = `post SELF average`, y = perc_test, color = Section)) +
geom_point(alpha = 0.7) +
geom_line(aes(y = predicted_mixed_beta), linewidth = 1) +
labs(
title = "Mixed Beta Regression: Percentage TOSLS vs Post SELF Average (by Section)",
x = "Post SELF Average",
y = "Percentage TOSLS Score (perc_test)"
) +
scale_color_manual(values = c("2" = "blue", "3" = "red")) +
theme_minimal()
## ----------------------------------------------------------
## What is the predictive relationship of self-perception
## and actual scientific literacy (TOSLS)?
## ----------------------------------------------------------
## -----------------------------------------------
## 1. Setup: Create delta-based and post-based data frames
## -----------------------------------------------
# Filter for complete cases for delta-based models
df_delta <- na.omit(df.std[, c("delta_test_percent", "delta_self", "Section")])
df_delta$Section <- as.factor(df_delta$Section)
# Filter for complete cases for post-score model
df_post <- na.omit(df.std[, c("perc_test", "post SELF average", "Section")])
df_post$Section <- as.factor(df_post$Section)
## -----------------------------------------------
## 2. OLS Model: Change in TOSLS vs. Change in SELF
## -----------------------------------------------
# Linear model (no random effects)
model_delta_ols <- lm(delta_test_percent ~ delta_self + Section, data = df_delta)
summary(model_delta_ols)
# Add predictions for plotting
df_delta$predicted_ols <- predict(model_delta_ols)
# Visualization
ggplot(df_delta, aes(x = delta_self, y = delta_test_percent, color = Section)) +
geom_point(alpha = 0.7) +
geom_line(aes(y = predicted_ols), linewidth = 1) +
labs(title = "OLS Model: ΔTOSLS vs ΔSELF",
x = "Change in SELF Score",
y = "Change in TOSLS Score (percent)") +
scale_color_manual(values = c("2" = "blue", "3" = "red")) +
theme_minimal()
## -----------------------------------------------
## 3. Mixed-Effects Model: ΔTOSLS ~ ΔSELF (random intercept by Section)
## -----------------------------------------------
model_delta_mixed <- lmer(delta_test_percent ~ delta_self + (1 | Section), data = df_delta)
summary(model_delta_mixed)
# Add predicted values for plotting
df_delta$predicted_mixed <- predict(model_delta_mixed)
# Visualization
ggplot(df_delta, aes(x = delta_self, y = delta_test_percent, color = Section)) +
geom_point(alpha = 0.7) +
geom_line(aes(y = predicted_mixed), linewidth = 1) +
labs(title = "Mixed Model: ΔTOSLS vs ΔSELF (Random Intercepts)",
x = "Change in SELF Score",
y = "Change in TOSLS Score (percent)") +
scale_color_manual(values = c("2" = "blue", "3" = "red")) +
theme_minimal()
## -----------------------------------------------
## 4. Mixed-Effects Model: Post-TOSLS ~ Post-SELF Average
## -----------------------------------------------
m_mixed_ols <- lmer(perc_test ~ `post SELF average` + (1 | Section), data = df_post)
summary(model_post_mixed)
# Model comparison of m_mixed_beta and m_mixed_ols
# Smaller AIC means better consideration of model complexity
AIC(m_mixed_beta, m_mixed_ols)
# Smaller BIC means better consideration of model complexity
BIC(m_mixed_beta, m_mixed_ols)
# Larger R squared means more error accounted for in model
r.squaredGLMM(m_mixed_ols)
r2(m_mixed_beta)
